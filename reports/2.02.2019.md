### Основная  концепция обучения уже в проде

1. Есть какая-то сторонная *policy*, которая рекомендует контент нашим пользователям и рядом с ней, пока что бездействую, находится бандит.
2. *Policy* выдает пользователю какой-то контент и параллельно мы считаем что бы выдал в данном случае бандит
3. Мы смотрм на реакцию пользователя на выдачу работающей *policy*:
⋅⋅* Если бандит совпал с *policy* и юзер ткнул на контент, то мы "обучаемся" на этом случае
⋅⋅* Иначе его пропускаем для бандита

 И так до тех пор, пока бандит не перебьет заданный порог. И дальше уже он будет выступать в качестве основного рекомендателя.
